<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Thomas  Tanay | Face Verification and Clustering</title>
    <meta name="author" content="Thomas  Tanay" />
    <meta name="description" content="PhD interruption" />
    <meta name="keywords" content="" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üí°</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://thomas-tanay.github.io/posts/2015-Face-Verification-and-Clustering">
    
    <!-- Dark Mode -->
    
  <script type="text/javascript">
    var _paq = _paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
    var u="//matomo.martinruenz.de/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '2']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
    })();
  </script>

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://thomas-tanay.github.io/">Thomas   <span class="font-weight-bold">Tanay</span></a>
          <!-- Navbar Toggle -->
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Face Verification and Clustering</h1>
  </header>

  <article class="post-content">
    <figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="/assets/img/bill-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/bill-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/bill-1400.webp" />
    Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/bill.png" title="header">

  </picture>

</figure>

<p>Location: iProov, Elizabeth House, 39 York Road, SE1 7NQ, London (UK).</p>

<p>Supervisor: Dr. Andrew Newell.</p>

<hr>

<h1> Context </h1>

<p>The combination of efficient data collection techniques and the use of deep convolutional neural networks allowing end-to-end learning 
has recently resulted in superhuman performance in face verification and clustering [<a href="https://arxiv.org/pdf/1411.7923.pdf" target="_blank" rel="noopener noreferrer">1</a>,<a href="https://arxiv.org/pdf/1503.03832.pdf" target="_blank" rel="noopener noreferrer">2</a>,<a href="https://www.robots.ox.ac.uk/%7Evgg/publications/2015/Parkhi15/parkhi15.pdf" target="_blank" rel="noopener noreferrer">3</a>].</p>

<p>This new approach is enabling new types of studies. 
Below I briefly describe how to use a pre-trained network to perform automatic labeling of a new dataset,
what the principal component of a standard dataset looks like in feature space, and who are the actresses and actors who most look like each other on the IMDb website
(according to a given network).</p>

<p>Note: these results were obtained in parallel to my actual work at iProov.</p>

<p><br></p>

<h1> Automatic Labeling </h1>

<p><u> 1) Download a pre-trained network: </u></p>

<ul>
  <li> <a href="https://cmusatyalab.github.io/openface/" target="_blank" rel="noopener noreferrer"> OpenFace (Torch) </a>  </li>
  <li> <a href="https://github.com/davidsandberg/facenet/" target="_blank" rel="noopener noreferrer"> FaceNet (Tensor Flow) </a>  </li>
  <li> <a href="http://www.vlfeat.org/matconvnet/pretrained/" target="_blank" rel="noopener noreferrer"> VGG-Face (MatConvNet) </a> </li>
</ul>

<p><br></p>

<p><u> 2) Download many pictures: </u></p>

<p>For instance by Googling ‚ÄúBill Murray‚Äù.</p>

<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="/assets/img/faces1-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/faces1-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/faces1-1400.webp" />
    Fallback to the original file -->
    <img class="img-fluid" src="/assets/img/faces1.png" title="faces1">

  </picture>

</figure>

<p><br></p>

<p><u> 3) Extract the faces: </u></p>

<p>For instance by using the simple Haar Cascades face detector from openCV.</p>

<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="/assets/img/faces2-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/faces2-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/faces2-1400.webp" />
    Fallback to the original file -->
    <img class="img-fluid" src="/assets/img/faces2.png" title="faces2">

  </picture>

</figure>

<p><br></p>

<p><u> 4) Remove the junk images: </u></p>

<p>The openCV face detector performs relatively poorly. Fortunately, the ‚Äújunk images‚Äù can easily be filtered out: 
their feature representations through the face network are ‚Äúflatter‚Äù than the feature representations of actual faces (their norms d are smaller).</p>

<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="/assets/img/faces3-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/faces3-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/faces3-1400.webp" />
    Fallback to the original file -->
    <img class="img-fluid" src="/assets/img/faces3.png" title="faces3">

  </picture>

</figure>

<p><br></p>

<p><u> 5) Remove anyone who's not Bill Murray: </u></p>

<p>The ‚ÄúBill Murray‚Äù cluster can be isolated by using a standard algorithm such as DBSCAN.</p>

<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="/assets/img/faces4-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/faces4-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/faces4-1400.webp" />
    Fallback to the original file -->
    <img class="img-fluid" src="/assets/img/faces4.png" title="faces4">

  </picture>

</figure>

<p><br></p>

<h1> First Principal Component </h1>

<p>Face networks are typically trained by enforcing <em>local</em> constraints in feature space: two pictures of a same individual should have feature representations which are close 
from each other and two pictures of different individuals should have feature representations which are far from each other. 
Here, we propose to study the <em>global</em> distribution resulting from these <em>local</em> constraints by computing the first principal component 
of the entire <em>Labeled Faces in the Wild</em> dataset.</p>

<p>Interestingly, we obtain a direction that separates the gender of individuals fairly reliably 
(note that <em>Labeled Faces in the Wild</em> is strongly imbalanced in favor of men):</p>

<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="/assets/img/1stPC-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/1stPC-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/1stPC-1400.webp" />
    Fallback to the original file -->
    <img class="img-fluid" src="/assets/img/1stPC.png" title="1stPC">

  </picture>

</figure>

<p>The network has spontaneously discovered the concept of gender: 
by learning to recognize identities, it has found that the population is constituted of two groups (women and men).</p>

<p><br></p>

<h1> Face Similarities </h1>

<p>We now compute the pairwise distances between the feature representations of the profile pictures of actresses and actors on the IMDb website (more precisely,
the actresses and actors in the <em>CASIA WebFace database</em>).</p>

<p>We show below the pairs of profile pictures corresponding to the smallest distances (i.e. the individuals who look most like each other according to our pre-trained network):</p>

<pre style="margin-top: 30px; margin-bottom: 30px;">
<img style="margin: 0px" width="1400" src="/assets/img/FaceSimilarities.png">
</pre>

<p>We can make two observations:</p>
<ul>
  <li> The two pairs of individuals who look most like each other are twins. </li>
  <li> Most of the pairs of individuals found are either women or belong to Black and Asian ethnic groups, <em>even though these groups are under-represented in the CASIA WebFace database</em>. <br>
  In other words, the pre-trained network is less sensitive to female and non-White facial features‚Äîa very serious algorithmic bias more and more recognized: <br>
  <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank" rel="noopener noreferrer">
  Facial Recognition Is Accurate, if You‚Äôre a White Guy (New York Times)
  </a>
  </li>
</ul>


  </article>

</div>

    </div>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

